import numpy as np 

input_neurons = 2 
hidden_neurons = 4 
output_neurons = 2 
iterations = 6000

# Initialization
input_data = np.random.randint(1, 5, input_neurons)
output_data = np.array([1.0, 0.0])
hidden_weights = np.random.rand(input_neurons, hidden_neurons)
output_weights = np.random.rand(hidden_neurons, output_neurons)
hidden_bias = np.random.rand(1, hidden_neurons)
output_bias = np.random.rand(1, output_neurons)

# Activation function (sigmoid) and its gradient
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Training
for i in range(iterations):
    hidden_layer = sigmoid(np.dot(input_data, hidden_weights) + hidden_bias)
    output_layer = sigmoid(np.dot(hidden_layer, output_weights) + output_bias)

    error = output_data - output_layer 
    gradient_output_layer = output_layer * (1 - output_layer)  # Simplified sigmoid gradient
    error_terms_output = gradient_output_layer * error 
    error_terms_hidden = hidden_layer * (1 - hidden_layer) * np.dot(error_terms_output, output_weights.T)

    hidden_weights += 0.05 * np.outer(input_data, error_terms_hidden)
    output_weights += 0.05 * np.outer(hidden_layer, error_terms_output)

    if i < 50 or i > iterations - 50:
        print("********") 
        print("iteration:", i, "::::", error) 
        print("###output########", output_layer)


#######***********output*************##########
********
iteration: 0 :::: [[ 0.0381971  -0.86699564]]
###output######## [[0.9618029  0.86699564]]
********
iteration: 1 :::: [[ 0.03824219 -0.86514623]]
###output######## [[0.96175781 0.86514623]]
********
iteration: 2 :::: [[ 0.03828724 -0.86325932]]
###output######## [[0.96171276 0.86325932]]
********
iteration: 3 :::: [[ 0.03833222 -0.86133411]]
###output######## [[0.96166778 0.86133411]]
********
iteration: 4 :::: [[ 0.03837712 -0.85936976]]
###output######## [[0.96162288 0.85936976]]
********
iteration: 5 :::: [[ 0.03842192 -0.85736544]]
###output######## [[0.96157808 0.85736544]]
********
iteration: 6 :::: [[ 0.03846659 -0.85532031]]
###output######## [[0.96153341 0.85532031]]
********
iteration: 7 :::: [[ 0.03851112 -0.85323352]]
###output######## [[0.96148888 0.85323352]]
********
iteration: 8 :::: [[ 0.03855549 -0.8511042 ]]
###output######## [[0.96144451 0.8511042 ]]
********
iteration: 9 :::: [[ 0.03859968 -0.84893149]]
###output######## [[0.96140032 0.84893149]]
********
iteration: 10 :::: [[ 0.03864366 -0.84671451]]
###output######## [[0.96135634 0.84671451]]
********
iteration: 11 :::: [[ 0.03868741 -0.84445239]]
###output######## [[0.96131259 0.84445239]]
********
iteration: 12 :::: [[ 0.03873092 -0.84214424]]
###output######## [[0.96126908 0.84214424]]
********
iteration: 13 :::: [[ 0.03877414 -0.83978918]]
###output######## [[0.96122586 0.83978918]]
********
iteration: 14 :::: [[ 0.03881707 -0.83738633]]
###output######## [[0.96118293 0.83738633]]
********
iteration: 15 :::: [[ 0.03885968 -0.83493481]]
###output######## [[0.96114032 0.83493481]]
********
iteration: 16 :::: [[ 0.03890193 -0.83243373]]
###output######## [[0.96109807 0.83243373]]
********
iteration: 17 :::: [[ 0.0389438  -0.82988222]]
###output######## [[0.9610562  0.82988222]]
********
iteration: 18 :::: [[ 0.03898526 -0.82727941]]
###output######## [[0.96101474 0.82727941]]
********
iteration: 19 :::: [[ 0.03902629 -0.82462445]]
###output######## [[0.96097371 0.82462445]]
********
iteration: 20 :::: [[ 0.03906685 -0.82191648]]
###output######## [[0.96093315 0.82191648]]
********
iteration: 21 :::: [[ 0.03910691 -0.81915468]]
###output######## [[0.96089309 0.81915468]]
********
iteration: 22 :::: [[ 0.03914644 -0.81633823]]
###output######## [[0.96085356 0.81633823]]
********
iteration: 23 :::: [[ 0.03918542 -0.81346633]]
###output######## [[0.96081458 0.81346633]]
********
iteration: 24 :::: [[ 0.0392238  -0.81053821]]
###output######## [[0.9607762  0.81053821]]
********
iteration: 25 :::: [[ 0.03926155 -0.80755312]]
###output######## [[0.96073845 0.80755312]]
********
iteration: 26 :::: [[ 0.03929864 -0.80451034]]
###output######## [[0.96070136 0.80451034]]
********
iteration: 27 :::: [[ 0.03933503 -0.80140918]]
###output######## [[0.96066497 0.80140918]]
********
iteration: 28 :::: [[ 0.0393707  -0.79824899]]
###output######## [[0.9606293  0.79824899]]
********
iteration: 29 :::: [[ 0.03940559 -0.79502917]]
###output######## [[0.96059441 0.79502917]]
********
iteration: 30 :::: [[ 0.03943968 -0.79174914]]
###output######## [[0.96056032 0.79174914]]
********
iteration: 31 :::: [[ 0.03947292 -0.78840837]]
###output######## [[0.96052708 0.78840837]]
********
iteration: 32 :::: [[ 0.03950528 -0.78500642]]
###output######## [[0.96049472 0.78500642]]
********
iteration: 33 :::: [[ 0.03953673 -0.78154285]]
###output######## [[0.96046327 0.78154285]]
********
iteration: 34 :::: [[ 0.03956721 -0.77801732]]
###output######## [[0.96043279 0.77801732]]
********
iteration: 35 :::: [[ 0.0395967  -0.77442953]]
###output######## [[0.9604033  0.77442953]]
********
iteration: 36 :::: [[ 0.03962515 -0.77077928]]
###output######## [[0.96037485 0.77077928]]
********
iteration: 37 :::: [[ 0.03965253 -0.7670664 ]]
###output######## [[0.96034747 0.7670664 ]]
********
iteration: 38 :::: [[ 0.03967879 -0.76329082]]
###output######## [[0.96032121 0.76329082]]
********
iteration: 39 :::: [[ 0.03970389 -0.75945257]]
###output######## [[0.96029611 0.75945257]]
********
iteration: 40 :::: [[ 0.0397278  -0.75555173]]
###output######## [[0.9602722  0.75555173]]
********
iteration: 41 :::: [[ 0.03975047 -0.75158848]]
###output######## [[0.96024953 0.75158848]]
********
iteration: 42 :::: [[ 0.03977187 -0.74756311]]
###output######## [[0.96022813 0.74756311]]
********
iteration: 43 :::: [[ 0.03979195 -0.74347598]]
###output######## [[0.96020805 0.74347598]]
********
iteration: 44 :::: [[ 0.03981069 -0.73932759]]
###output######## [[0.96018931 0.73932759]]
********
iteration: 45 :::: [[ 0.03982803 -0.73511849]]
###output######## [[0.96017197 0.73511849]]
********
iteration: 46 :::: [[ 0.03984396 -0.73084938]]
###output######## [[0.96015604 0.73084938]]
********
iteration: 47 :::: [[ 0.03985842 -0.72652104]]
###output######## [[0.96014158 0.72652104]]
********
iteration: 48 :::: [[ 0.03987138 -0.72213439]]
###output######## [[0.96012862 0.72213439]]
********
iteration: 49 :::: [[ 0.03988281 -0.71769044]]
###output######## [[0.96011719 0.71769044]]
********
iteration: 5951 :::: [[ 0.01658239 -0.02200199]]
###output######## [[0.98341761 0.02200199]]
********
iteration: 5952 :::: [[ 0.01658147 -0.02199998]]
###output######## [[0.98341853 0.02199998]]
********
iteration: 5953 :::: [[ 0.01658055 -0.02199796]]
###output######## [[0.98341945 0.02199796]]
********
iteration: 5954 :::: [[ 0.01657963 -0.02199595]]
###output######## [[0.98342037 0.02199595]]
********
iteration: 5955 :::: [[ 0.01657871 -0.02199394]]
###output######## [[0.98342129 0.02199394]]
********
iteration: 5956 :::: [[ 0.01657778 -0.02199193]]
###output######## [[0.98342222 0.02199193]]
********
iteration: 5957 :::: [[ 0.01657686 -0.02198992]]
###output######## [[0.98342314 0.02198992]]
********
iteration: 5958 :::: [[ 0.01657595 -0.02198791]]
###output######## [[0.98342405 0.02198791]]
********
iteration: 5959 :::: [[ 0.01657503 -0.0219859 ]]
###output######## [[0.98342497 0.0219859 ]]
********
iteration: 5960 :::: [[ 0.01657411 -0.0219839 ]]
###output######## [[0.98342589 0.0219839 ]]
********
iteration: 5961 :::: [[ 0.01657319 -0.02198189]]
###output######## [[0.98342681 0.02198189]]
********
iteration: 5962 :::: [[ 0.01657227 -0.02197988]]
###output######## [[0.98342773 0.02197988]]
********
iteration: 5963 :::: [[ 0.01657135 -0.02197787]]
###output######## [[0.98342865 0.02197787]]
********
iteration: 5964 :::: [[ 0.01657043 -0.02197587]]
###output######## [[0.98342957 0.02197587]]
********
iteration: 5965 :::: [[ 0.01656951 -0.02197386]]
###output######## [[0.98343049 0.02197386]]
********
iteration: 5966 :::: [[ 0.01656859 -0.02197186]]
###output######## [[0.98343141 0.02197186]]
********
iteration: 5967 :::: [[ 0.01656767 -0.02196985]]
###output######## [[0.98343233 0.02196985]]
********
iteration: 5968 :::: [[ 0.01656676 -0.02196785]]
###output######## [[0.98343324 0.02196785]]
********
iteration: 5969 :::: [[ 0.01656584 -0.02196585]]
###output######## [[0.98343416 0.02196585]]
********
iteration: 5970 :::: [[ 0.01656492 -0.02196384]]
###output######## [[0.98343508 0.02196384]]
********
iteration: 5971 :::: [[ 0.016564   -0.02196184]]
###output######## [[0.983436   0.02196184]]
********
iteration: 5972 :::: [[ 0.01656308 -0.02195984]]
###output######## [[0.98343692 0.02195984]]
********
iteration: 5973 :::: [[ 0.01656217 -0.02195784]]
###output######## [[0.98343783 0.02195784]]
********
iteration: 5974 :::: [[ 0.01656125 -0.02195584]]
###output######## [[0.98343875 0.02195584]]
********
iteration: 5975 :::: [[ 0.01656033 -0.02195384]]
###output######## [[0.98343967 0.02195384]]
********
iteration: 5976 :::: [[ 0.01655942 -0.02195184]]
###output######## [[0.98344058 0.02195184]]
********
iteration: 5977 :::: [[ 0.0165585  -0.02194984]]
###output######## [[0.9834415  0.02194984]]
********
iteration: 5978 :::: [[ 0.01655758 -0.02194784]]
###output######## [[0.98344242 0.02194784]]
********
iteration: 5979 :::: [[ 0.01655667 -0.02194584]]
###output######## [[0.98344333 0.02194584]]
********
iteration: 5980 :::: [[ 0.01655575 -0.02194384]]
###output######## [[0.98344425 0.02194384]]
********
iteration: 5981 :::: [[ 0.01655483 -0.02194185]]
###output######## [[0.98344517 0.02194185]]
********
iteration: 5982 :::: [[ 0.01655392 -0.02193985]]
###output######## [[0.98344608 0.02193985]]
********
iteration: 5983 :::: [[ 0.016553   -0.02193785]]
###output######## [[0.983447   0.02193785]]
********
iteration: 5984 :::: [[ 0.01655209 -0.02193586]]
###output######## [[0.98344791 0.02193586]]
********
iteration: 5985 :::: [[ 0.01655117 -0.02193386]]
###output######## [[0.98344883 0.02193386]]
********
iteration: 5986 :::: [[ 0.01655025 -0.02193187]]
###output######## [[0.98344975 0.02193187]]
********
iteration: 5987 :::: [[ 0.01654934 -0.02192987]]
###output######## [[0.98345066 0.02192987]]
********
iteration: 5988 :::: [[ 0.01654842 -0.02192788]]
###output######## [[0.98345158 0.02192788]]
********
iteration: 5989 :::: [[ 0.01654751 -0.02192589]]
###output######## [[0.98345249 0.02192589]]
********
iteration: 5990 :::: [[ 0.01654659 -0.0219239 ]]
###output######## [[0.98345341 0.0219239 ]]
********
iteration: 5991 :::: [[ 0.01654568 -0.0219219 ]]
###output######## [[0.98345432 0.0219219 ]]
********
iteration: 5992 :::: [[ 0.01654477 -0.02191991]]
###output######## [[0.98345523 0.02191991]]
********
iteration: 5993 :::: [[ 0.01654385 -0.02191792]]
###output######## [[0.98345615 0.02191792]]
********
iteration: 5994 :::: [[ 0.01654294 -0.02191593]]
###output######## [[0.98345706 0.02191593]]
********
iteration: 5995 :::: [[ 0.01654202 -0.02191394]]
###output######## [[0.98345798 0.02191394]]
********
iteration: 5996 :::: [[ 0.01654111 -0.02191195]]
###output######## [[0.98345889 0.02191195]]
********
iteration: 5997 :::: [[ 0.0165402  -0.02190996]]
###output######## [[0.9834598  0.02190996]]
********
iteration: 5998 :::: [[ 0.01653928 -0.02190798]]
###output######## [[0.98346072 0.02190798]]
********
iteration: 5999 :::: [[ 0.01653837 -0.02190599]]
###output######## [[0.98346163 0.02190599]]

Process finished with exit code 0
